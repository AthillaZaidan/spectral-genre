{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Classification\n",
    "## SVD + MFCC + Spectral Features with SVM\n",
    "\n",
    "**Objective:** Achieve 75-80% accuracy on GTZAN dataset\n",
    "\n",
    "**Method:** Enhanced SVD from STFT + MFCC + Spectral features + SVM classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "import librosa\n",
    "from scipy.linalg import svd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "import joblib\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original'\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 1: Loading Dataset\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "audio_data = []\n",
    "labels = []\n",
    "file_paths = []\n",
    "\n",
    "genres = ['blues', 'classical', 'country', 'disco', 'hiphop', \n",
    "          'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "\n",
    "for genre in genres:\n",
    "    genre_path = Path(DATASET_PATH) / genre\n",
    "    audio_files = list(genre_path.glob('*.wav'))\n",
    "    \n",
    "    print(f\"Loading {genre}...\", end=' ')\n",
    "    for audio_file in audio_files:\n",
    "        try:\n",
    "            audio, sr = librosa.load(audio_file, sr=22050, duration=30)\n",
    "            audio_data.append(audio)\n",
    "            labels.append(genre)\n",
    "            file_paths.append(str(audio_file))\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError loading {audio_file.name}: {e}\")\n",
    "    \n",
    "    print(f\"Done - {len([l for l in labels if l == genre])} files\")\n",
    "\n",
    "print(f\"\\nTotal files loaded: {len(audio_data)}\")\n",
    "print(f\"Genres: {len(genres)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_svd_enhanced(audio, n_components=50, sr=22050):\n",
    "    \"\"\"Extract SVD features from STFT with statistics\"\"\"\n",
    "    try:\n",
    "        stft = librosa.stft(audio, n_fft=2048, hop_length=512, window='hann')\n",
    "        combined = np.vstack([stft.real, stft.imag])\n",
    "        _, s, _ = svd(combined, full_matrices=False)\n",
    "        \n",
    "        svd_feat = s[:n_components]\n",
    "        svd_stats = [\n",
    "            np.mean(svd_feat),\n",
    "            np.std(svd_feat),\n",
    "            np.max(svd_feat),\n",
    "            np.min(svd_feat),\n",
    "            np.median(svd_feat),\n",
    "            np.percentile(svd_feat, 25),\n",
    "            np.percentile(svd_feat, 75),\n",
    "            np.sum(svd_feat) / np.sum(s[:100])\n",
    "        ]\n",
    "        return np.concatenate([svd_feat, svd_stats])\n",
    "    except:\n",
    "        return np.zeros(n_components + 8)\n",
    "\n",
    "\n",
    "def extract_mfcc_enhanced(audio, sr=22050):\n",
    "    \"\"\"Extract enhanced MFCC features\"\"\"\n",
    "    features = []\n",
    "    try:\n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=20)\n",
    "        features.extend(np.mean(mfcc, axis=1))\n",
    "        features.extend(np.std(mfcc, axis=1))\n",
    "        \n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "        features.extend(np.mean(mfcc_delta, axis=1))\n",
    "        \n",
    "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "        features.extend(np.mean(mfcc_delta2, axis=1))\n",
    "    except:\n",
    "        features = [0] * 80\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "def extract_spectral_enhanced(audio, sr=22050):\n",
    "    \"\"\"Extract enhanced spectral features\"\"\"\n",
    "    features = []\n",
    "    try:\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=audio, sr=sr)\n",
    "        features.extend([np.mean(spec_cent), np.std(spec_cent)])\n",
    "        \n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=audio, sr=sr)\n",
    "        features.extend([np.mean(spec_bw), np.std(spec_bw)])\n",
    "        \n",
    "        spec_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)\n",
    "        features.extend([np.mean(spec_rolloff), np.std(spec_rolloff)])\n",
    "        \n",
    "        spec_contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)\n",
    "        features.extend(np.mean(spec_contrast, axis=1))\n",
    "        features.extend(np.std(spec_contrast, axis=1))\n",
    "        \n",
    "        spec_flat = librosa.feature.spectral_flatness(y=audio)\n",
    "        features.extend([np.mean(spec_flat), np.std(spec_flat)])\n",
    "        \n",
    "        rms = librosa.feature.rms(y=audio)\n",
    "        features.extend([np.mean(rms), np.std(rms)])\n",
    "        \n",
    "        zcr = librosa.feature.zero_crossing_rate(audio)\n",
    "        features.extend([np.mean(zcr), np.std(zcr)])\n",
    "    except:\n",
    "        features = [0] * 26\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "def extract_all_features(audio, sr=22050):\n",
    "    \"\"\"Combine all features\"\"\"\n",
    "    svd_feat = extract_svd_enhanced(audio, n_components=50, sr=sr)\n",
    "    mfcc_feat = extract_mfcc_enhanced(audio, sr=sr)\n",
    "    spectral_feat = extract_spectral_enhanced(audio, sr=sr)\n",
    "    return np.concatenate([svd_feat, mfcc_feat, spectral_feat])\n",
    "\n",
    "\n",
    "print(\"Feature extraction functions defined!\")\n",
    "print(\"\\nFeature Configuration:\")\n",
    "print(\"  - SVD: 50 singular values + 8 statistics = 58 features\")\n",
    "print(\"  - MFCC: 20 coefficients Ã— 4 (mean, std, delta, delta2) = 80 features\")\n",
    "print(\"  - Spectral: Various spectral features with mean + std = 26 features\")\n",
    "print(\"  - Total: 164 features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract Features from All Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 2: Feature Extraction\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nExtracting features from all audio files...\")\n",
    "print(\"(This will take approximately 15-20 minutes)\\n\")\n",
    "\n",
    "features_list = []\n",
    "start_time = time.time()\n",
    "\n",
    "for i, audio in enumerate(tqdm(audio_data, desc=\"Extracting\")):\n",
    "    feat = extract_all_features(audio)\n",
    "    features_list.append(feat)\n",
    "\n",
    "features_array = np.array(features_list)\n",
    "extraction_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nFeature extraction completed!\")\n",
    "print(f\"Time taken: {extraction_time/60:.1f} minutes\")\n",
    "print(f\"Feature matrix shape: {features_array.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 3: Train-Test Split\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_array, \n",
    "    labels, \n",
    "    test_size=0.2, \n",
    "    stratify=labels, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "train_dist = pd.Series(y_train).value_counts().sort_index()\n",
    "test_dist = pd.Series(y_test).value_counts().sort_index()\n",
    "\n",
    "print(\"\\nDistribution per genre:\")\n",
    "print(f\"{'Genre':<12} {'Train':<8} {'Test':<8}\")\n",
    "print(\"-\" * 30)\n",
    "for genre in genres:\n",
    "    print(f\"{genre:<12} {train_dist[genre]:<8} {test_dist[genre]:<8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Preprocessing (Scaling & Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 4: Preprocessing\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nScaling features with RobustScaler...\")\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(\"Scaling completed\")\n",
    "\n",
    "print(\"\\nSelecting top 100 features using mutual information...\")\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=100)\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "print(f\"Feature selection completed\")\n",
    "print(f\"Final feature shape: {X_train_selected.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Training (Multiple Configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 5: Model Training\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nTraining SVM with multiple configurations...\\n\")\n",
    "\n",
    "configs = [\n",
    "    {'C': 100, 'gamma': 0.01, 'name': 'Config 1'},\n",
    "    {'C': 50, 'gamma': 0.1, 'name': 'Config 2'},\n",
    "    {'C': 200, 'gamma': 0.001, 'name': 'Config 3'},\n",
    "    {'C': 10, 'gamma': 'scale', 'name': 'Config 4'},\n",
    "]\n",
    "\n",
    "best_acc = 0\n",
    "best_model = None\n",
    "best_config = None\n",
    "\n",
    "for config in configs:\n",
    "    print(f\"Testing {config['name']}: C={config['C']}, gamma={config['gamma']}...\", end=' ')\n",
    "    \n",
    "    svm = SVC(\n",
    "        kernel='rbf',\n",
    "        C=config['C'],\n",
    "        gamma=config['gamma'],\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    svm.fit(X_train_selected, y_train)\n",
    "    y_pred = svm.predict(X_test_selected)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.2%}\")\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_model = svm\n",
    "        best_config = config\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"Best Model: {best_config['name']}\")\n",
    "print(f\"  C = {best_config['C']}\")\n",
    "print(f\"  gamma = {best_config['gamma']}\")\n",
    "print(f\"  Accuracy = {best_acc:.2%}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 6: Model Evaluation\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "y_pred_final = best_model.predict(X_test_selected)\n",
    "\n",
    "print(\"\\nOverall Performance:\")\n",
    "print(f\"  Test Accuracy: {best_acc:.2%}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_final))\n",
    "\n",
    "print(\"\\nPer-Genre Accuracy:\")\n",
    "for genre in genres:\n",
    "    mask = np.array(y_test) == genre\n",
    "    if np.sum(mask) > 0:\n",
    "        genre_acc = accuracy_score(\n",
    "            np.array(y_test)[mask], \n",
    "            np.array(y_pred_final)[mask]\n",
    "        )\n",
    "        print(f\"  {genre:<12}: {genre_acc:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_final, labels=genres)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    xticklabels=genres,\n",
    "    yticklabels=genres,\n",
    "    cbar_kws={'label': 'Count'}\n",
    ")\n",
    "plt.title(f'Confusion Matrix\\nTest Accuracy: {best_acc:.1%}', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Saved: confusion_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-genre performance bar chart\n",
    "genre_accuracies = []\n",
    "for genre in genres:\n",
    "    mask = np.array(y_test) == genre\n",
    "    if np.sum(mask) > 0:\n",
    "        acc = accuracy_score(np.array(y_test)[mask], np.array(y_pred_final)[mask])\n",
    "        genre_accuracies.append(acc)\n",
    "    else:\n",
    "        genre_accuracies.append(0)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "bars = plt.bar(genres, genre_accuracies, color='steelblue', alpha=0.8, edgecolor='black')\n",
    "plt.axhline(y=best_acc, color='red', linestyle='--', linewidth=2, label=f'Overall: {best_acc:.1%}')\n",
    "plt.axhline(y=0.75, color='green', linestyle='--', linewidth=2, label='Target: 75%')\n",
    "\n",
    "for i, (bar, acc) in enumerate(zip(bars, genre_accuracies)):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "             f'{acc:.1%}', ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "\n",
    "plt.xlabel('Genre', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "plt.title('Per-Genre Classification Accuracy', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylim(0, 1.1)\n",
    "plt.legend(fontsize=11, loc='lower right')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('genre_accuracy.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Saved: genre_accuracy.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 8: Saving Results\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save model\n",
    "model_package = {\n",
    "    'scaler': scaler,\n",
    "    'feature_selector': selector,\n",
    "    'model': best_model,\n",
    "    'config': best_config,\n",
    "    'accuracy': best_acc,\n",
    "    'genres': genres\n",
    "}\n",
    "joblib.dump(model_package, 'music_genre_classifier.pkl')\n",
    "print(\"Saved: music_genre_classifier.pkl\")\n",
    "\n",
    "# Save results to CSV\n",
    "results_data = {\n",
    "    'Genre': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F1-Score': [],\n",
    "    'Support': [],\n",
    "    'Accuracy': []\n",
    "}\n",
    "\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    y_test, y_pred_final, labels=genres, average=None\n",
    ")\n",
    "\n",
    "for i, genre in enumerate(genres):\n",
    "    results_data['Genre'].append(genre)\n",
    "    results_data['Precision'].append(precision[i])\n",
    "    results_data['Recall'].append(recall[i])\n",
    "    results_data['F1-Score'].append(f1[i])\n",
    "    results_data['Support'].append(support[i])\n",
    "    results_data['Accuracy'].append(genre_accuracies[i])\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "results_df.to_csv('classification_results.csv', index=False)\n",
    "print(\"Saved: classification_results.csv\")\n",
    "\n",
    "print(\"\\nResults table:\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"  Test Accuracy: {best_acc:.2%}\")\n",
    "print(f\"  Target: 75-80%\")\n",
    "\n",
    "if best_acc >= 0.75:\n",
    "    print(f\"  Status: TARGET ACHIEVED!\")\n",
    "else:\n",
    "    print(f\"  Status: Need {(0.75 - best_acc)*100:.1f} more percentage points\")\n",
    "\n",
    "print(f\"\\nBest Performing Genres:\")\n",
    "top_3 = sorted(zip(genres, genre_accuracies), key=lambda x: x[1], reverse=True)[:3]\n",
    "for i, (genre, acc) in enumerate(top_3, 1):\n",
    "    print(f\"  {i}. {genre.capitalize()}: {acc:.1%}\")\n",
    "\n",
    "print(f\"\\nChallenging Genres:\")\n",
    "bottom_3 = sorted(zip(genres, genre_accuracies), key=lambda x: x[1])[:3]\n",
    "for i, (genre, acc) in enumerate(bottom_3, 1):\n",
    "    print(f\"  {i}. {genre.capitalize()}: {acc:.1%}\")\n",
    "\n",
    "print(f\"\\nSaved Files:\")\n",
    "print(f\"  - music_genre_classifier.pkl\")\n",
    "print(f\"  - classification_results.csv\")\n",
    "print(f\"  - confusion_matrix.png\")\n",
    "print(f\"  - genre_accuracy.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
